{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dbnfinal1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oFAxQlSfesQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f01fc67a-5f75-488a-da74-59deabb9ae63"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yjW296n-yMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "from keras import regularizers\n",
        "from sklearn.neural_network import BernoulliRBM\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import preprocessing\n",
        "from keras import layers\n",
        "import pandas as pd\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7rl7C4uSsRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DBN():\n",
        "    def __init__(\n",
        "            self,\n",
        "            x_train,\n",
        "            y_train,\n",
        "            x_test,\n",
        "            y_test,\n",
        "            hidden_layer,\n",
        "            learning_rate_rbm=0.002,\n",
        "            batch_size_rbm=1,\n",
        "            n_epochs_rbm=2000,\n",
        "            verbose_rbm=1,\n",
        "            random_seed_rbm=1300,\n",
        "            activation_function_nn='relu',\n",
        "            learning_rate_nn=0.002,\n",
        "            batch_size_nn=10,\n",
        "            n_epochs_nn=800,\n",
        "            verbose_nn=1,\n",
        "            decay_rate=0):\n",
        "\n",
        "        self.x_train = x_train\n",
        "        self.y_train = y_train\n",
        "        self.x_test = x_test\n",
        "        self.y_test = y_test\n",
        "        self.hidden_layer = hidden_layer\n",
        "        self.learning_rate_rbm = learning_rate_rbm\n",
        "        self.batch_size_rbm = batch_size_rbm\n",
        "        self.n_epochs_rbm = n_epochs_rbm\n",
        "        self.verbose_rbm = verbose_rbm\n",
        "        self.random_seed = random_seed_rbm\n",
        "        self.activation_function_nn = activation_function_nn\n",
        "        self.learning_rate_nn = learning_rate_nn\n",
        "        self.batch_size_nn = batch_size_nn\n",
        "        self.n_epochs_nn = n_epochs_nn\n",
        "        self.verbose_nn = verbose_nn\n",
        "        self.decay_rate = decay_rate\n",
        "        self.weight_rbm = []\n",
        "        self.bias_rbm = []\n",
        "        self.test_rms = 0\n",
        "        self.result = []\n",
        "        self.model = Sequential()\n",
        "\n",
        "    def pretraining(self):\n",
        "        input_layer = self.x_train\n",
        "        for i in range(len(self.hidden_layer)):\n",
        "            print(\"DBN Layer {0} Pre-training\".format(i + 1))\n",
        "            rbm = BernoulliRBM(n_components=self.hidden_layer[i],\n",
        "                               learning_rate=self.learning_rate_rbm,\n",
        "                               batch_size=self.batch_size_rbm,\n",
        "                               n_iter=self.n_epochs_rbm,\n",
        "                               verbose=self.verbose_rbm,\n",
        "                               random_state=self.verbose_rbm)\n",
        "            rbm.fit(input_layer)\n",
        "            # size of weight matrix is [input_layer, hidden_layer]\n",
        "            self.weight_rbm.append(rbm.components_.T)\n",
        "            self.bias_rbm.append(rbm.intercept_hidden_)\n",
        "            input_layer = rbm.transform(input_layer)\n",
        "        print('Pre-training finish.')\n",
        "\n",
        "    def finetuning(self):\n",
        "        print('Fine-tuning start.')\n",
        "\n",
        "        for i in range(0, len(self.hidden_layer)):\n",
        "            if i == 0:\n",
        "                self.model.add(Dense(self.hidden_layer[i], activation=self.activation_function_nn,\n",
        "                                     input_dim=self.x_train.shape[1]))\n",
        "            elif i >= 1:\n",
        "                self.model.add(Dense(self.hidden_layer[i], activation=self.activation_function_nn))\n",
        "            else:\n",
        "                pass\n",
        "            layer = self.model.layers[i]\n",
        "            layer.set_weights([self.weight_rbm[i], self.bias_rbm[i]])\n",
        "        print(self.y_train.shape[1])\n",
        "        if (self.y_train.ndim == 1):\n",
        "            self.model.add(Dense(1, activation=None, kernel_regularizer=regularizers.l2(0.01)))\n",
        "        else:\n",
        "            self.model.add(Dense(70, activation='relu'))\n",
        "            self.model.add(Dense(100, activation='relu'))\n",
        "            self.model.add(Dense(120, activation='relu'))\n",
        "            self.model.add(Dense(140, activation='relu'))\n",
        "            self.model.add(Dense(160, activation='relu'))\n",
        "\n",
        "            self.model.add(Dense(self.y_train.shape[1], activation=None))\n",
        "\n",
        "        sgd = SGD(lr=self.learning_rate_nn, decay=self.decay_rate)\n",
        "        self.model.compile(loss='mse',\n",
        "                           optimizer=sgd,\n",
        "                           )\n",
        "        history=self.model.fit(self.x_train, self.y_train, batch_size=self.batch_size_nn,\n",
        "                       epochs=self.n_epochs_nn, verbose=self.verbose_nn)\n",
        "        print('Fine-tuning finish.')\n",
        "        self.test_rms = self.model.evaluate(self.x_test, self.y_test)\n",
        "        self.result = np.array(self.model.predict(self.x_test))\n",
        "\n",
        "\n",
        "    def predict(self, series):\n",
        "        return np.array(self.model.predict(series))\n",
        "\n",
        "def datagen(path1,path2,path3,path4):\n",
        "    Data,label, Test,testlabel= [],[],[],[]\n",
        "    Data1,labels,Test1,testlabel1 = [],[],[],[]\n",
        "\n",
        "    with open(path1, 'r', encoding='gb18030', errors='ignore') as f1:\n",
        "        csv_reader1 = csv.reader(f1)\n",
        "        for row in csv_reader1:\n",
        "            Data.append(row)\n",
        "    with open(path2, 'r', encoding='gb18030', errors='ignore') as f2:\n",
        "        csv_reader2 = csv.reader(f2)\n",
        "        for row in csv_reader2:\n",
        "            label.append(row)\n",
        "    with open(path3, 'r', encoding='gb18030', errors='ignore') as f3:\n",
        "        csv_reader3 = csv.reader(f3)\n",
        "        for row in csv_reader3:\n",
        "            Test.append(row)\n",
        "    with open(path4, 'r', encoding='gb18030', errors='ignore') as f4:\n",
        "        csv_reader4 = csv.reader(f4)\n",
        "        for row in csv_reader4:\n",
        "            testlabel.append(row)\n",
        "\n",
        "    #mix the dataset\n",
        "    idx = np.random.randint(1, len(Data), len(Data)-1)\n",
        "    for i in range(len(idx)):\n",
        "        ax = Data[idx[i]][:]\n",
        "        bx = label[idx[i]][:]\n",
        "        Data1.append(ax)\n",
        "        labels.append(bx)\n",
        "\n",
        "    for i in range(1,len(Test)-1):\n",
        "        cx = Test[i][:]\n",
        "        dx = testlabel[i][:]\n",
        "        Test1.append(cx)\n",
        "        testlabel1.append(dx)\n",
        "\n",
        "    X = np.empty((len(Data1), 141), dtype=np.float32)\n",
        "    Y = np.empty((len(Data1), 137), dtype=np.float32)\n",
        "    Z = np.empty((len(Test1), 141), dtype=np.float32)\n",
        "    Q = np.empty((len(Test1), 137), dtype=np.float32)\n",
        "\n",
        "    for i in range(len(Data1)):\n",
        "        X[i,] = Data1[i]\n",
        "        Y[i,] = labels[i]\n",
        "    for j in range(len(Test1)):\n",
        "        Z[j,] = Test1[j]\n",
        "        Q[j,] = testlabel1[j]\n",
        "        #print(Z[j,5], Z[j,40], Z[j,80], Z[j,120])\n",
        "\n",
        "    \n",
        "    xx = preprocessing.minmax_scale(X, feature_range=(0, 1), axis=0, copy=True)\n",
        "    yy = preprocessing.minmax_scale(Y, feature_range=(0, 1), axis=0, copy=True)\n",
        "    zz = preprocessing.minmax_scale(Z, feature_range=(0, 1), axis=0, copy=True)\n",
        "    qq = preprocessing.minmax_scale(Q, feature_range=(0, 1), axis=0, copy=True)\n",
        "    print(xx)\n",
        "\n",
        "    return xx,yy,zz,Q\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    path1='drive/My Drive/Colab Notebooks/final_project/in.csv'\n",
        "    path2='drive/My Drive/Colab Notebooks/final_project/out.csv'\n",
        "    path3='drive/My Drive/Colab Notebooks/final_project/inr.csv'\n",
        "    path4 ='drive/My Drive/Colab Notebooks/final_project/outr.csv'\n",
        "    trX,trY,teX,teY=datagen(path1,path2,path3,path4)\n",
        "    ax=DBN(trX,trY,teX,teY,[80,30])\n",
        "    ax.pretraining()\n",
        "    ax.finetuning()\n",
        "\n",
        "    Q = np.empty((len(teX), 137), dtype=np.float32)\n",
        "    for i in range(len(teX)):\n",
        "        y = teX[i]\n",
        "        y1 = teY[i]\n",
        "        y2 = ax.predict(y.reshape(1, 141))\n",
        "        mn = MinMaxScaler()\n",
        "        qq= mn.fit_transform(teY)\n",
        "        qq[i]=y2[0]\n",
        "        qq=mn.inverse_transform(qq)\n",
        "        y3=qq[i]\n",
        "        Q[i,] = y3\n",
        "\n",
        "        #plot\n",
        "        x = range(1, len(y1) + 1)\n",
        "        plt.plot(x, y1, 'b', c='r', label='real')\n",
        "        plt.plot(x, y3, 'b', c='g', label='predicted')\n",
        "        plt.title('real and test predicted')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    # save in csv\n",
        "    #data2 = pd.DataFrame(Q)\n",
        "    #data2.to_csv('drive/My Drive/Colab Notebooks/final_project/test2.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlK7E_joGzNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}